---
# YAML anchors
s3_credentials: &s3_credentials
  access_key_id: ((s3_access_key_id))
  secret_access_key: ((s3_secret_access_key))
  endpoint: ((s3_endpoint))
  region_name: ((s3_region_name))
  skip_ssl_verification: true
  use_path_style: true

resources:
- name: platform-automation-custom-image
  type: s3
  source:
    <<: *s3_credentials
    bucket: binaries
    regexp: platauto-uaac-(.*).tar.gz

jobs:
- name: free-space-on-harbor-vm
  plan:
  - get: platform-automation-custom-image
    params:
      unpack: true
  - task: delete-pivotal-files-from-worker
    image: platform-automation-custom-image
    config:
      platform: linux
      params:
        DOCKER_HOST: "harbor.elasticsky.cloud" #((docker_host))
        WORKER_NAME: concourse-worker-1
        DOCKER_PASS: VMware123!
      run:
        path: bash
        args:
        - -c
        - |
          set -eux
          echo "Connecting to @$DOCKER_HOST to delete pivotal files from worker $WORKER_NAME"
          command="docker exec $WORKER_NAME find /worker-state/volumes/live -name *pivotal* -type f -delete"
          sshpass -p "$DOCKER_PASS" ssh -o StrictHostKeyChecking=no "ubuntu@$DOCKER_HOST" "$command"
